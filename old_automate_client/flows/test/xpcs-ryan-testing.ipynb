{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate XPCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globus_automate_client import (create_flows_client, graphviz_format, state_colors_for_log,\n",
    "                                    get_access_token_for_scope, create_action_client, \n",
    "                                    create_flows_client)\n",
    "from IPython.display import display, display_svg, clear_output\n",
    "from ipywidgets import widgets\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "\n",
    "\n",
    "sys.path.append(\".\")\n",
    "os.environ['JUPYTER_PATH'] = '.'\n",
    "CLIENT_ID = \"e6c75d97-532a-4c88-b031-8584a319fa3e\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funcX\n",
    "\n",
    "Deine the analysis and plotting functions used in the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_ep = 'cdee5fd4-7f6f-4561-a13e-d5431ef0cc8e'\n",
    "theta_ep = '5e0d6d3d-3495-4a3e-a44b-6e22731e25f6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ff918fed-ab3a-47b4-ac27-1477d8809942\n"
     ]
    }
   ],
   "source": [
    "def alcf_xpcs_corr(event):\n",
    "    import time\n",
    "    import json\n",
    "    import subprocess\n",
    "    from subprocess import PIPE\n",
    "    \n",
    "    print(\"Starting XPCS Corr\")\n",
    "    \n",
    "    hdf_file = event['data']['hdf']\n",
    "    imm_file = event['data']['imm']\n",
    "    \n",
    "    cmd = f\"/soft/datascience/xpcs_eigen/build/corr {hdf_file} -imm {imm_file}\"\n",
    "    cmd = cmd.split(\" \")\n",
    "    \n",
    "    res = subprocess.run(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    print(res.stdout)\n",
    "    print(res.stderr)\n",
    "    return str(res.stdout)\n",
    "\n",
    "alcf_xpcs_corr_func_uuid = fxc.register_function(alcf_xpcs_corr, description=\"An XPCS corr function.\")\n",
    "print(alcf_xpcs_corr_func_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9cf28a71-a863-43e4-bbf8-cc348d0cfc47\n"
     ]
    }
   ],
   "source": [
    "def plot_xpcs(event):\n",
    "    import os\n",
    "    import time\n",
    "    import json\n",
    "    import shutil\n",
    "    import pickle\n",
    "    import subprocess\n",
    "    from subprocess import PIPE\n",
    "    \n",
    "    hdf_file = event['data']['hdf']\n",
    "    hdf_file_name = hdf_file.split(\"/\")[-1]\n",
    "    exp_name = \".\".join(hdf_file.split(\"/\")[-1].split(\".\")[:-1])\n",
    "    \n",
    "    dir_name = \"/\".join(hdf_file.split('/')[:-1])\n",
    "\n",
    "    os.chdir(dir_name)\n",
    "    \n",
    "    python = '/home/rchard/.conda/envs/funcx-theta/bin/python'\n",
    "    xpcs_plot = '/home/rchard/APSDataAnalysis/tools/pilot1-tools/scripts/xpcs_plots.py'\n",
    "    xpcs_meta = '/home/rchard/APSDataAnalysis/tools/pilot1-tools/scripts/xpcs_metadata.py'\n",
    "    xpcs_qc = '/home/rchard/APSDataAnalysis/tools/pilot1-tools/scripts/xpcs_qc.py'\n",
    "\n",
    "    cmd = f\"{python} {xpcs_plot} {hdf_file}\"\n",
    "    print(cmd)\n",
    "    cmd = cmd.split(\" \")\n",
    "    res = subprocess.run(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    print(res.stdout)\n",
    "    \n",
    "    cmd = f\"{python} {xpcs_meta} gather {hdf_file}\"\n",
    "    print(cmd)\n",
    "    \n",
    "    my_env = os.environ.copy()\n",
    "    my_env[\"LC_ALL\"] = \"C.UTF-8\"\n",
    "    my_env[\"LANG\"] = \"C.UTF-8\"\n",
    "    \n",
    "    cmd = cmd.split(\" \")\n",
    "    res = subprocess.run(cmd, stdout=PIPE, stderr=PIPE, env=my_env)\n",
    "    print(res.stdout)\n",
    "    print(res.stderr) \n",
    "    return str(res.stderr)\n",
    "    return cmd\n",
    "    return 'done'\n",
    "\n",
    "plot_xpcs_func_uuid = fxc.register_function(plot_xpcs, description=\"An XPCS corr function.\")\n",
    "print(plot_xpcs_func_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3855d06-8b4e-4a54-9b39-f16c0532febe\n"
     ]
    }
   ],
   "source": [
    "def alcf_xpcs_pilot(event):\n",
    "    import time\n",
    "    import json\n",
    "    import subprocess\n",
    "    from subprocess import PIPE\n",
    "    \n",
    "    print(\"Starting XPCS Pilot\")\n",
    "    \n",
    "    meta_file = event['data']['metadata']\n",
    "    exp_name = event['data']['hdf'].split(\"/\")[-1].replace(\".hdf\", \"\")\n",
    "    \n",
    "    pilot = '/home/rchard/.conda/envs/funcx-theta/bin/pilot'\n",
    "\n",
    "    cmd = f\"{pilot} upload -u -j {meta_file} {exp_name} /\"\n",
    "    print(cmd)\n",
    "    \n",
    "    res = subprocess.run(cmd.split(\" \"), stdout=PIPE, stderr=PIPE,\n",
    "    env={'LC_ALL': 'C.UTF-8', 'LANG': 'C.UTF-8'})\n",
    "    \n",
    "    print(res.stdout)\n",
    "    print(res.stderr)\n",
    "    return str(res.stdout)\n",
    "    \n",
    "pilot_func_uuid = fxc.register_function(alcf_xpcs_pilot, description=\"An XPCS pilot function.\")\n",
    "print(pilot_func_uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate XPCS\n",
    "\n",
    "Combine using the functions with Automate to first transfer data to Theta, use funcX, then return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This flow does not return the result to APS.\n",
    "\n",
    "flow_definition = {\n",
    "  \"Comment\": \"Automate XPCS\",\n",
    "  \"StartAt\": \"Transfer1\",\n",
    "  \"States\": {\n",
    "    \"Transfer1\": {\n",
    "      \"Comment\": \"Initial Transfer from APS to ALCF\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://actions.automate.globus.org/transfer/transfer\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/actions.globus.org/transfer/transfer\",\n",
    "      \"InputPath\": \"$.Transfer1Input\",\n",
    "      \"ResultPath\": \"$.Transfer1Result\",\n",
    "      \"WaitTime\": 6000,\n",
    "      \"Next\": \"Transfer2\"\n",
    "    },\n",
    "    \"Transfer2\": {\n",
    "      \"Comment\": \"Second Transfer from APS to ALCF\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://actions.automate.globus.org/transfer/transfer\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/actions.globus.org/transfer/transfer\",\n",
    "      \"InputPath\": \"$.Transfer2Input\",\n",
    "      \"ResultPath\": \"$.Transfer2Result\",\n",
    "      \"WaitTime\": 6000,\n",
    "      \"Next\": \"ExecCorr\"\n",
    "    },\n",
    "    \"ExecCorr\": {\n",
    "      \"Comment\": \"Use corr to process the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://dev.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "      \"InputPath\": \"$.Exec1Input\",\n",
    "      \"ResultPath\": \"$.Exec1Result\",\n",
    "      \"WaitTime\": 12000,\n",
    "      \"Next\": \"ExecPlots\"\n",
    "    },\n",
    "    \"ExecPlots\": {\n",
    "      \"Comment\": \"Generate plots from the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://dev.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "      \"InputPath\": \"$.Exec2Input\",\n",
    "      \"ResultPath\": \"$.Exec2Result\",\n",
    "      \"WaitTime\": 12000,\n",
    "      \"Next\": \"ExecPilot\"\n",
    "    },\n",
    "    \"ExecPilot\": {\n",
    "      \"Comment\": \"Generate plots from the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "      \"InputPath\": \"$.Exec3Input\",\n",
    "      \"ResultPath\": \"$.Exec3Result\",\n",
    "      \"WaitTime\": 12000,\n",
    "      \"End\": True\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This flow does not return the result to APS.\n",
    "\n",
    "flow_definition = {\n",
    "  \"Comment\": \"Automate XPCS\",\n",
    "  \"StartAt\": \"ExecCorr\",\n",
    "  \"States\": {\n",
    "    \"ExecCorr\": {\n",
    "      \"Comment\": \"Use corr to process the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://dev.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "      \"InputPath\": \"$.Exec1Input\",\n",
    "      \"ResultPath\": \"$.Exec1Result\",\n",
    "      \"WaitTime\": 12000,\n",
    "      \"Next\": \"ExecPlots\"\n",
    "    },\n",
    "    \"ExecPlots\": {\n",
    "      \"Comment\": \"Generate plots from the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://dev.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "      \"InputPath\": \"$.Exec2Input\",\n",
    "      \"ResultPath\": \"$.Exec2Result\",\n",
    "      \"WaitTime\": 12000,\n",
    "      \"Next\": \"ExecPilot\"\n",
    "    },\n",
    "    \"ExecPilot\": {\n",
    "      \"Comment\": \"Generate plots from the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "      \"InputPath\": \"$.Exec3Input\",\n",
    "      \"ResultPath\": \"$.Exec3Result\",\n",
    "      \"WaitTime\": 12000,\n",
    "      \"End\": True\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobusHTTPResponse({'administered_by': [], 'api_version': '1.0', 'definition': {'Comment': 'Automate XPCS', 'StartAt': 'ExecCorr', 'States': {'ExecCorr': {'ActionScope': 'https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2', 'ActionUrl': 'https://dev.funcx.org/automate', 'Comment': 'Use corr to process the data', 'InputPath': '$.Exec1Input', 'Next': 'ExecPlots', 'ResultPath': '$.Exec1Result', 'Type': 'Action', 'WaitTime': 12000}, 'ExecPilot': {'ActionScope': 'https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2', 'ActionUrl': 'https://funcx.org/automate', 'Comment': 'Generate plots from the data', 'End': True, 'InputPath': '$.Exec3Input', 'ResultPath': '$.Exec3Result', 'Type': 'Action', 'WaitTime': 12000}, 'ExecPlots': {'ActionScope': 'https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2', 'ActionUrl': 'https://dev.funcx.org/automate', 'Comment': 'Generate plots from the data', 'InputPath': '$.Exec2Input', 'Next': 'ExecPilot', 'ResultPath': '$.Exec2Result', 'Type': 'Action', 'WaitTime': 12000}}}, 'description': '', 'globus_auth_scope': 'https://auth.globus.org/scopes/8a83c8e1-44cd-447a-8297-5ce7702d75b2/flow_8a83c8e1_44cd_447a_8297_5ce7702d75b2', 'globus_auth_username': '8a83c8e1-44cd-447a-8297-5ce7702d75b2@clients.auth.globus.org', 'id': '8a83c8e1-44cd-447a-8297-5ce7702d75b2', 'keywords': [], 'log_supported': True, 'principal_urn': 'urn:globus:auth:identity:8a83c8e1-44cd-447a-8297-5ce7702d75b2', 'runnable_by': [], 'subtitle': '', 'synchronous': False, 'title': 'XPCS', 'types': ['Action'], 'visible_to': []})\n",
      "GlobusHTTPResponse({'administered_by': [], 'api_version': '1.0', 'definition': {'Comment': 'Automate XPCS', 'StartAt': 'ExecCorr', 'States': {'ExecCorr': {'ActionScope': 'https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2', 'ActionUrl': 'https://dev.funcx.org/automate', 'Comment': 'Use corr to process the data', 'InputPath': '$.Exec1Input', 'Next': 'ExecPlots', 'ResultPath': '$.Exec1Result', 'Type': 'Action', 'WaitTime': 12000}, 'ExecPilot': {'ActionScope': 'https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2', 'ActionUrl': 'https://funcx.org/automate', 'Comment': 'Generate plots from the data', 'End': True, 'InputPath': '$.Exec3Input', 'ResultPath': '$.Exec3Result', 'Type': 'Action', 'WaitTime': 12000}, 'ExecPlots': {'ActionScope': 'https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2', 'ActionUrl': 'https://dev.funcx.org/automate', 'Comment': 'Generate plots from the data', 'InputPath': '$.Exec2Input', 'Next': 'ExecPilot', 'ResultPath': '$.Exec2Result', 'Type': 'Action', 'WaitTime': 12000}}}, 'description': '', 'globus_auth_scope': 'https://auth.globus.org/scopes/8a83c8e1-44cd-447a-8297-5ce7702d75b2/flow_8a83c8e1_44cd_447a_8297_5ce7702d75b2', 'globus_auth_username': '8a83c8e1-44cd-447a-8297-5ce7702d75b2@clients.auth.globus.org', 'id': '8a83c8e1-44cd-447a-8297-5ce7702d75b2', 'keywords': [], 'log_supported': True, 'principal_urn': 'urn:globus:auth:identity:8a83c8e1-44cd-447a-8297-5ce7702d75b2', 'runnable_by': [], 'subtitle': '', 'synchronous': False, 'title': 'XPCS', 'types': ['Action'], 'visible_to': []})\n",
      "Newly created flow with id:\n",
      "8a83c8e1-44cd-447a-8297-5ce7702d75b2\n",
      "and scope:\n",
      "https://auth.globus.org/scopes/8a83c8e1-44cd-447a-8297-5ce7702d75b2/flow_8a83c8e1_44cd_447a_8297_5ce7702d75b2\n"
     ]
    }
   ],
   "source": [
    "flows_client = create_flows_client(CLIENT_ID)\n",
    "flow = flows_client.deploy_flow(flow_definition, title=\"XPCS\")\n",
    "from pprint import pprint\n",
    "pprint(flow)\n",
    "flow_id = flow.data['id']\n",
    "print(flow)\n",
    "flow_scope = flow['globus_auth_scope']\n",
    "print(f'Newly created flow with id:\\n{flow_id}\\nand scope:\\n{flow_scope}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"157pt\" height=\"194pt\"\n",
       " viewBox=\"0.00 0.00 157.00 194.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 190)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-190 153,-190 153,4 -4,4\"/>\n",
       "<!-- ExecCorr -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>ExecCorr</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"149,-186 0,-186 0,-148 149,-148 149,-186\"/>\n",
       "<text text-anchor=\"start\" x=\"48.5\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ExecCorr</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">InputPath: $.Exec1Input</text>\n",
       "</g>\n",
       "<!-- ExecPlots -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>ExecPlots</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"149,-112 0,-112 0,-74 149,-74 149,-112\"/>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ExecPlots</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">InputPath: $.Exec2Input</text>\n",
       "</g>\n",
       "<!-- ExecCorr&#45;&gt;ExecPlots -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>ExecCorr&#45;&gt;ExecPlots</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M74.5,-147.9432C74.5,-140.1493 74.5,-130.9538 74.5,-122.3381\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.0001,-122.2494 74.5,-112.2495 71.0001,-122.2495 78.0001,-122.2494\"/>\n",
       "</g>\n",
       "<!-- ExecPilot -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ExecPilot</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"149,-38 0,-38 0,0 149,0 149,-38\"/>\n",
       "<text text-anchor=\"start\" x=\"48\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ExecPilot</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">InputPath: $.Exec3Input</text>\n",
       "</g>\n",
       "<!-- ExecPlots&#45;&gt;ExecPilot -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>ExecPlots&#45;&gt;ExecPilot</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M74.5,-73.9432C74.5,-66.1493 74.5,-56.9538 74.5,-48.3381\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.0001,-48.2494 74.5,-38.2495 71.0001,-48.2495 78.0001,-48.2494\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fbed6754b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_resp = flows_client.get_flow(flow_id)\n",
    "flow_def = get_resp.data['definition']\n",
    "flow_graph = graphviz_format(flow_def)\n",
    "display(flow_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to serialize inputs for funcX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_fx_inputs(*args, **kwargs):\n",
    "    from funcx.serialize import FuncXSerializer\n",
    "    fx_serializer = FuncXSerializer()\n",
    "    ser_args = fx_serializer.serialize(args)\n",
    "    ser_kwargs = fx_serializer.serialize(kwargs)\n",
    "    payload = fx_serializer.pack_buffers([ser_args, ser_kwargs])\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "01\n",
      "gAMpLg==\n",
      "486\n",
      "01\n",
      "gAN9cQBYBQAAAGV2ZW50cQF9cQJYBAAAAGRhdGFxA31xBChYAwAAAGhkZnEFWFYAAAAvcHJvamVj\n",
      "dHMvQVBTRGF0YUFuYWx5c2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdf\n",
      "dGVzdF8wMDFfMDAwMS0wMjU2LmhkZnEGWAMAAABpbW1xB1hYAAAAL3Byb2plY3RzL0FQU0RhdGFB\n",
      "bmFseXNpcy9BdXRvbWF0ZS9BMDQ3X3Rlc3RfMDAxXzAwMDEtMDI1Ni9BMDQ3X3Rlc3RfMDAxXzAw\n",
      "MDAxLTAwMjU2LmltbXEIWAgAAABtZXRhZGF0YXEJWFcAAAAvcHJvamVjdHMvQVBTRGF0YUFuYWx5\n",
      "c2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdfdGVzdF8wMDFfMDAwMS0w\n",
      "MjU2Lmpzb25xCnVzcy4=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "event = {\"data\": {\n",
    "         \"hdf\": \"/projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_0001-0256.hdf\",\n",
    "         \"imm\": \"/projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_00001-00256.imm\",\n",
    "         \"metadata\": \"/projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_0001-0256.json\"\n",
    "     }}\n",
    "funcx_payload = serialize_fx_inputs(event=event)\n",
    "print(funcx_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_input = {\n",
    "  \"Transfer1Input\": {\n",
    "    \"source_endpoint_id\": \"b0e921df-6d04-11e5-ba46-22000b92c6ec\",\n",
    "    \"destination_endpoint_id\": \"08925f04-569f-11e7-bef8-22000b9a448b\",\n",
    "    \"transfer_items\": [\n",
    "      {\n",
    "        \"source_path\": \"/data/xpcs8/2019-1/comm201901/cluster_results/A001_Aerogel_1mm_att6_Lq0_001_0001-1000.hdf\",\n",
    "        \"destination_path\": \"/projects/APSDataAnalysis/Automate/A001_Aerogel.hdf\",\n",
    "        \"recursive\": False\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"Transfer2Input\": {\n",
    "    \"source_endpoint_id\": \"b0e921df-6d04-11e5-ba46-22000b92c6ec\",\n",
    "    \"destination_endpoint_id\": \"08925f04-569f-11e7-bef8-22000b9a448b\",\n",
    "    \"transfer_items\": [\n",
    "      {\n",
    "        \"source_path\": \"/data/xpcs8/2019-1/comm201901/A001_Aerogel_1mm_att6_Lq0_001/A001_Aerogel_1mm_att6_Lq0_001_00001-01000.imm\",\n",
    "        \"destination_path\": \"/projects/APSDataAnalysis/Automate/A001_Aerogel.imm\",\n",
    "        \"recursive\": False\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"Exec1Input\": {\n",
    "    \"endpoint\":theta_ep,\n",
    "     \"func\":alcf_xpcs_corr_func_uuid,\n",
    "     \"payload\": funcx_payload\n",
    "  },\n",
    "  \"Exec2Input\": {\n",
    "    \"endpoint\":theta_ep,\n",
    "     \"func\":plot_xpcs_func_uuid,\n",
    "     \"payload\": funcx_payload\n",
    "  },\n",
    "  \"Exec3Input\": {\n",
    "      \"endpoint\": login_ep,\n",
    "      \"func\": pilot_func_uuid,\n",
    "      \"payload\": funcx_payload\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobusHTTPResponse({'action_id': '769f2686-f7a3-4d34-a46b-d1767c1999b7', 'completion_time': 'None', 'created_by': 'urn:globus:auth:identity:c4765424-d274-11e5-b894-cb4139f74ecf', 'details': {'code': 'ActionStarted', 'description': 'State ExecCorr of type Action started', 'details': {'input': {'Exec1Input': {'endpoint': '5e0d6d3d-3495-4a3e-a44b-6e22731e25f6', 'func': 'ff918fed-ab3a-47b4-ac27-1477d8809942', 'payload': '12\\n01\\ngAMpLg==\\n486\\n01\\ngAN9cQBYBQAAAGV2ZW50cQF9cQJYBAAAAGRhdGFxA31xBChYAwAAAGhkZnEFWFYAAAAvcHJvamVj\\ndHMvQVBTRGF0YUFuYWx5c2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdf\\ndGVzdF8wMDFfMDAwMS0wMjU2LmhkZnEGWAMAAABpbW1xB1hYAAAAL3Byb2plY3RzL0FQU0RhdGFB\\nbmFseXNpcy9BdXRvbWF0ZS9BMDQ3X3Rlc3RfMDAxXzAwMDEtMDI1Ni9BMDQ3X3Rlc3RfMDAxXzAw\\nMDAxLTAwMjU2LmltbXEIWAgAAABtZXRhZGF0YXEJWFcAAAAvcHJvamVjdHMvQVBTRGF0YUFuYWx5\\nc2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdfdGVzdF8wMDFfMDAwMS0w\\nMjU2Lmpzb25xCnVzcy4=\\n'}, 'Exec2Input': {'endpoint': '5e0d6d3d-3495-4a3e-a44b-6e22731e25f6', 'func': '9cf28a71-a863-43e4-bbf8-cc348d0cfc47', 'payload': '12\\n01\\ngAMpLg==\\n486\\n01\\ngAN9cQBYBQAAAGV2ZW50cQF9cQJYBAAAAGRhdGFxA31xBChYAwAAAGhkZnEFWFYAAAAvcHJvamVj\\ndHMvQVBTRGF0YUFuYWx5c2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdf\\ndGVzdF8wMDFfMDAwMS0wMjU2LmhkZnEGWAMAAABpbW1xB1hYAAAAL3Byb2plY3RzL0FQU0RhdGFB\\nbmFseXNpcy9BdXRvbWF0ZS9BMDQ3X3Rlc3RfMDAxXzAwMDEtMDI1Ni9BMDQ3X3Rlc3RfMDAxXzAw\\nMDAxLTAwMjU2LmltbXEIWAgAAABtZXRhZGF0YXEJWFcAAAAvcHJvamVjdHMvQVBTRGF0YUFuYWx5\\nc2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdfdGVzdF8wMDFfMDAwMS0w\\nMjU2Lmpzb25xCnVzcy4=\\n'}, 'Exec3Input': {'endpoint': 'cdee5fd4-7f6f-4561-a13e-d5431ef0cc8e', 'func': '3bd39ec3-bbcc-4090-a588-f3ca1289a82b', 'payload': '12\\n01\\ngAMpLg==\\n486\\n01\\ngAN9cQBYBQAAAGV2ZW50cQF9cQJYBAAAAGRhdGFxA31xBChYAwAAAGhkZnEFWFYAAAAvcHJvamVj\\ndHMvQVBTRGF0YUFuYWx5c2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdf\\ndGVzdF8wMDFfMDAwMS0wMjU2LmhkZnEGWAMAAABpbW1xB1hYAAAAL3Byb2plY3RzL0FQU0RhdGFB\\nbmFseXNpcy9BdXRvbWF0ZS9BMDQ3X3Rlc3RfMDAxXzAwMDEtMDI1Ni9BMDQ3X3Rlc3RfMDAxXzAw\\nMDAxLTAwMjU2LmltbXEIWAgAAABtZXRhZGF0YXEJWFcAAAAvcHJvamVjdHMvQVBTRGF0YUFuYWx5\\nc2lzL0F1dG9tYXRlL0EwNDdfdGVzdF8wMDFfMDAwMS0wMjU2L0EwNDdfdGVzdF8wMDFfMDAwMS0w\\nMjU2Lmpzb25xCnVzcy4=\\n'}, 'Transfer1Input': {'destination_endpoint_id': '08925f04-569f-11e7-bef8-22000b9a448b', 'source_endpoint_id': 'b0e921df-6d04-11e5-ba46-22000b92c6ec', 'transfer_items': [{'destination_path': '/projects/APSDataAnalysis/Automate/A001_Aerogel.hdf', 'recursive': False, 'source_path': '/data/xpcs8/2019-1/comm201901/cluster_results/A001_Aerogel_1mm_att6_Lq0_001_0001-1000.hdf'}]}, 'Transfer2Input': {'destination_endpoint_id': '08925f04-569f-11e7-bef8-22000b9a448b', 'source_endpoint_id': 'b0e921df-6d04-11e5-ba46-22000b92c6ec', 'transfer_items': [{'destination_path': '/projects/APSDataAnalysis/Automate/A001_Aerogel.imm', 'recursive': False, 'source_path': '/data/xpcs8/2019-1/comm201901/A001_Aerogel_1mm_att6_Lq0_001/A001_Aerogel_1mm_att6_Lq0_001_00001-01000.imm'}]}}, 'state_name': 'ExecCorr', 'state_type': 'Action'}, 'time': '2019-11-07T18:52:10.636000+00:00'}, 'start_time': '2019-11-07T18:52:10.610000+00:00', 'status': 'ACTIVE'})\n",
      "Flow action started with id: 769f2686-f7a3-4d34-a46b-d1767c1999b7\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: ACTIVE\n",
      "Flow status: FAILED\n"
     ]
    }
   ],
   "source": [
    "flow_action = flows_client.run_flow(flow_id, flow_scope, flow_input)\n",
    "print(flow_action)\n",
    "flow_action_id = flow_action['action_id']\n",
    "flow_status = flow_action['status']\n",
    "print(f'Flow action started with id: {flow_action_id}')\n",
    "while flow_status == 'ACTIVE':\n",
    "    time.sleep(10)\n",
    "    flow_action = flows_client.flow_action_status(flow_id, flow_scope, flow_action_id)\n",
    "    flow_status = flow_action['status']\n",
    "    print(f'Flow status: {flow_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Pilot ingest\n",
    "\n",
    "Need to figure out either using -s or renaming the directory the data is being processed in. Perhaps easiest if we just force everything to be worked on in the experiment name dir? then do a chdir to that exp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4f63f171-a154-4a02-98a1-3d27551017a4\n"
     ]
    }
   ],
   "source": [
    "def alcf_xpcs_pilot(event):\n",
    "    import os\n",
    "    import time\n",
    "    import json\n",
    "    import subprocess\n",
    "    from subprocess import PIPE\n",
    "    \n",
    "    print(\"Starting XPCS Pilot\")\n",
    "    \n",
    "    meta_file = event['data']['metadata']\n",
    "    exp_dir = \"/\".join(event['data']['hdf'].split(\"/\")[:-1])\n",
    "    exp_name = event['data']['hdf'].split(\"/\")[-1].replace(\".hdf\", \"\")\n",
    "    \n",
    "    os.chdir(exp_dir)\n",
    "    \n",
    "    pilot = '/home/rchard/.conda/envs/funcx-theta/bin/pilot'\n",
    "\n",
    "    cmd = f\"{pilot} upload -u -j {meta_file} {exp_name} /\"\n",
    "    print(cmd)\n",
    "    return cmd\n",
    "    res = subprocess.run(cmd.split(\" \"), stdout=PIPE, stderr=PIPE,\n",
    "    env={'LC_ALL': 'C.UTF-8', 'LANG': 'C.UTF-8'})\n",
    "    \n",
    "    print(res.stdout)\n",
    "    print(res.stderr)\n",
    "    return str(res.stdout)\n",
    "\n",
    "pilot_func_uuid = fxc.register_function(alcf_xpcs_pilot, description=\"An XPCS pilot function.\")\n",
    "print(pilot_func_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1c8fb1c-8155-468f-a81a-80cab3ddacc2\n"
     ]
    }
   ],
   "source": [
    "event = {\"data\": {\n",
    "         \"hdf\": \"/projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_0001-0256.hdf\",\n",
    "         \"imm\": \"/projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_00001-00256.imm\",\n",
    "         \"metadata\": \"/projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_0001-0256.json\"\n",
    "     }}\n",
    "res = fxc.run(event, endpoint_id=login_ep, function_id=pilot_func_uuid)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rchard/.conda/envs/funcx-theta/bin/pilot upload -u -j /projects/APSDataAnalysis/Automate/A047_test_001_0001-0256/A047_test_001_0001-0256.json A047_test_001_0001-0256 /\n"
     ]
    }
   ],
   "source": [
    "print(fxc.get_result(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b''\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from funcx.serialize import FuncXSerializer\n",
    "fx_serializer = FuncXSerializer()\n",
    "res = '01\\ngANYAwAAAGInJ3EALg==\\n'\n",
    "\n",
    "x = fx_serializer.deserialize(res)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hdf(event):\n",
    "    import os\n",
    "    import shutil\n",
    "    from XPCS.scripts.xpcs_metadata import gather\n",
    "    from XPCS.scripts.xpcs_plots import make_plots\n",
    "    from XPCS.scripts.xpcs_qc import check_hdf_dataset\n",
    "    from pilot.client import PilotClient\n",
    "\n",
    "    hdf_file = event['data']['hdf']\n",
    "    hdf_dir, extension = os.path.splitext(hdf_file)\n",
    "    try:\n",
    "        os.mkdir(hdf_dir)\n",
    "        shutil.move(hdf_file, hdf_dir)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    hdf_file = os.path.join(hdf_dir, os.path.basename(hdf_file))\n",
    "    os.chdir(hdf_dir)\n",
    "    assert os.path.exists(hdf_file), 'HDF File {hdf_file} does not exist!'\n",
    "\n",
    "    if check_hdf_dataset(hdf_file) is False:\n",
    "        print('HDF Check failed, skipping...')\n",
    "        return {}\n",
    "    metadata = gather(hdf_file)\n",
    "    make_plots(hdf_file)\n",
    "    metadata.update(event['custom_metadata'])\n",
    "    pc = PilotClient()\n",
    "    uploaded_metadata = pc.register(hdf_dir, '/', metadata=metadata,\n",
    "                                    update=True, skip_analysis=True)\n",
    "    print('Everything worked, register called')\n",
    "    return uploaded_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_hdf_func_uuid = fxc.register_function(\n",
    "    process_hdf, description=\"Put hdf file into dir, make plots, gather metadata.\"\n",
    ")\n",
    "print(process_hdf_func_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/Users/nick/globus/aps/globus-automation/XPCS/data/A001_Aerogel_1mm_att3_Lq0_001_0001-1000.hdf'\n",
    "payload = {\n",
    "    'data': {\n",
    "        \"hdf\": f\"{fname}\"\n",
    "    },\n",
    "    'custom_metadata': {\n",
    "        \"description\": f\"{fname}: Automated data processing.\",\n",
    "        \"creators\": [{\"creatorName\": \"8-ID\"}],\n",
    "        \"publisher\": \"Automate\",\n",
    "        \"title\": fname,\n",
    "        \"subjects\": [{\"subject\": \"XPCS\"}, {\"subject\": \"8-ID\"}],\n",
    "        \"publicationYear\": \"2019\",\n",
    "        \"resourceType\": {\n",
    "            \"resourceType\": \"Dataset\",\n",
    "            \"resourceTypeGeneral\": \"Dataset\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = fxc.run(payload, endpoint_id=local_ep, function_id=process_hdf_func_uuid)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)\n",
    "fxc.get_result(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
